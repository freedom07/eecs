# PRML 목차
1. 소개 - 확률론, 결정이론, 정보이론
    - Example: Polynomial Curve Fitting
    - Probability Theory
    - Model Selection
    - The Curse of Dimensionality
    - Decision Theory
    - Information Theory
2. 확률 분포 (Probability Distributions)
    - Binary Variable
    - Multinomial Variables
    - The Gaussian Distribution
    - The Exponential Family
    - NonParametric Methods
3. 회귀 선형 모델 (Linear Models for Regression)
    - Linear Basis Function Models
    - The Bias-Variance Decompositiion
    - Bayesian Linear Regression
    - Bayesian Model Comparison
    - The Evidence Approximation
    - Limitations of Fixed Basis Fucntions
4. 분류 선형 모델 (Linear Models for 
Classification)
    - Discriminant Functions
    - Probabilistic Generative Models
    - Probabilistic Discriminative Models
    - The Laplace Approximation
    - Bayesian Logistic Regression
5. 신경망 (Neural Network)
    - Feed-forward Network Functions
    - Network Training
    - Error Backpropagation
    - The Hessian Matrix
    - Regularization in Neural Network
    - Mixture Density Networks
    - Bayesian Neural Network
6. 커널 방법론 (Kernel Method)
    - Dual Representation
    - Constructing Kernels
    - Radial Basis Function Networks
    - Gaussian Process 
7. 희소 커널 (Sparse Kernel Machines)
    - <u>Maximum Margin Classifier(SVM)</u>
    - Relevance Vector Machine(RVM)
8. 그래픽 모델 (Graphical Models)
    - <u>Bayesian Network</u>
    - Conditional Independence
    - Markov Random Fields(마르코프 무작위장)
    - <u>Inference in Graphical Models</u>
9. 혼합 모델과 EM (Mixture Models and EM)
    - K-means Clustering
    - Mixture of Gaussian
    - An Alternative View of EM
    - The EM algorithms in General
10. 근사 추론 (Approximate Inference)
    - Variational Inference
    - Illustration: Variation Mixture of Gaussian
    - Variational Linear Regression
    - Exponential Family Distributions
    - Local Variational Methods
    - Variational Logistic Regression
    - Expectation Propagation
11. 샘플링 (Sampling Methods)
    - <u>Basic sampling algorithms</u>
    - <u>Markov Chain Monte Carlo</u>
    - <u>Gibbs Sampling</u>
    - Slice Sampling
    - The Hybrid Monte Carlo Algorihm
    - Estimating the Parition Function
12. 연속 잠재 변수(Continuous Latent Variable)
    - <u>Principle Component Analysis(PCA)</u>
    - Probabilistic PCA
    - Kernel PCA
    - Nonlinear Latent Variable Models
13. 순차 데이터(Sequential Data)
    - <u>Markov Models</u>
    - <u>Hidden Mardov Models</u>
    - Linear Dynamical System(LDS)
14. 모델 조합(Combining Models)
    - Bayesian Model Averaging
    - Committeees
    - Boosting
    - Tree-based Models
    - Conditional Mixture Models

# 목차
1. Decision Tree
2. Geometric view of classification and NN
3. MLE(Maximum Likelihood Estimation) & MAP
4. Naive Bayes Classifier
5. Linear Regression
6. Bias-Variance Tradeoff
7. Perceptron
8. Support Vector Machine(SVM)
9. Unsupervised Learning: K-means, GMM
10. Unsupervised Learning: PCA
11. Unsupervised Learning: LDA
12. Emsemble: Boosting and Bagging
13. Deep Neural Network Architectures
